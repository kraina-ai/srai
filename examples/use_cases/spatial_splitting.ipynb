{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Spatial splitting with stratification\n",
    "\n",
    "SRAI library contains a dedicated functions for splitting the points dataset into train / test (and optionally validation) splits by separating the points spatially while also keeping them stratified based on a given target.\n",
    "\n",
    "The function only works for points dataset and uses [`H3`](https://h3geo.org/) indexing system to cluster points together and separate H3 cells into different splits.\n",
    "\n",
    "---\n",
    "\n",
    "When working with most machine learning datasets, splitting into training and testing sets is straightforward: pick a random subset for testing, and (optionally) use stratification to keep the distribution of a target variable balanced between the two. This works fine when the data points are independent.\n",
    "\n",
    "Geospatial data plays by different rules. Nearby locations often share similar characteristics - a phenomenon called spatial autocorrelation. If we split data randomly, our training and test sets might end up covering the same areas, meaning the model is “tested” on locations that are practically identical to ones it has already seen. This can make performance look much better than it really is and we can't test its capability to generalize the reasoning based on spatial features. \n",
    "\n",
    "That’s why for geo-related tasks, we need spatial splitting: making sure the training and test sets are separated in space so that evaluation reflects real-world conditions. Sometimes we also want to stratify these spatial splits by a numerical value to ensure both sets still have similar value distributions. Standard `train_test_split` functions can’t combine these two needs, so we provide a dedicated function for spatially aware splitting with optional stratification.\n",
    "\n",
    "---\n",
    "\n",
    "This notebook will show how different modes of splitting work based on buildings dataset from [Overture Maps Foundation](https://overturemaps.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "### How does it work?\n",
    "\n",
    "To separate the input dataset into multiple outputs, H3 indexing system is used to split groups of points together.\n",
    "\n",
    "First, the algorithm transform the points into H3 cells with a given resolution and calculates statistics per H3 cell (number of points per bucket / category).\n",
    "\n",
    "Next, all H3 cells are shuffled (with optional `random_state` to ensure reproducibility) and iterated one by one.\n",
    "\n",
    "For each split (test, validation, test) and each bucket per split, a current number of points is saved. While iterating each H3 cell with a group of points inside it, a potential new number of points is calculated with a difference to the expected ratio. Current H3 cell is assigned to the split where the difference to the expected ratio is the lowest.\n",
    "\n",
    "After iterating all H3 cells, the original dataset of points is split based on the list of assigned H3 cells.\n",
    "\n",
    "The report of splitting is printed with differences between expected and actual ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextily as cx\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import overturemaestro as om\n",
    "import pyarrow.compute as pc\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "from srai.h3 import h3_to_geoseries, shapely_geometry_to_h3\n",
    "from srai.spatial_split import spatial_split_points, train_test_spatial_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "Let's start with downloading example data. Here we will use Vancouver buildings from Overture Maps dataset.\n",
    "\n",
    "We only want buildings with both `height` and `subtype` columns filled.\n",
    "\n",
    "Height will be used in the numerical split example and subtype in the categorical split example.\n",
    "\n",
    "---\n",
    "\n",
    "Because the splitting only works on points, we will assign a centroid to each building as an additional column. Centroids will be calculated in the corresponding projected Coordinate Reference System."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "VANCOUVER_BOUNDING_BOX = (-123.148670, 49.255555, -123.076572, 49.296907)\n",
    "VANCOUVER_PROJECTED_CRS = 26910  # NAD83 / UTM zone 10N\n",
    "H3_RESOLUTION = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings = om.convert_bounding_box_to_geodataframe(\n",
    "    theme=\"buildings\",\n",
    "    type=\"building\",\n",
    "    bbox=VANCOUVER_BOUNDING_BOX,\n",
    "    release=\"2025-07-23.0\",\n",
    "    pyarrow_filter=pc.field(\"subtype\").is_valid() & pc.field(\"height\").is_valid(),\n",
    "    columns_to_download=[\"subtype\", \"height\"],\n",
    ")\n",
    "buildings[\"centroid\"] = buildings.to_crs(VANCOUVER_PROJECTED_CRS).centroid.to_crs(4326)\n",
    "buildings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Without target column - default\n",
    "\n",
    "Target column isn't required for spatial splitting.\n",
    "\n",
    "By default, the algorithm calculates a density of points per H3 cell and uses it for the for stratification. This way both splits have both dense and sparse regions in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_default_gdf, test_default_gdf = train_test_spatial_split(\n",
    "    input_gdf=buildings,\n",
    "    parent_h3_resolution=H3_RESOLUTION,\n",
    "    geometry_column=\"centroid\",\n",
    "    target_column=None,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")\n",
    "train_default_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "covering_h3_cells = h3_to_geoseries(shapely_geometry_to_h3(buildings[\"centroid\"], H3_RESOLUTION))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = train_default_gdf.plot(color=\"royalblue\", figsize=(15, 15), label=\"train\", legend=True)\n",
    "test_default_gdf.plot(color=\"orange\", ax=ax, label=\"test\", legend=True)\n",
    "covering_h3_cells.boundary.plot(color=\"black\", ax=ax, linewidth=0.3)\n",
    "\n",
    "ax.set_title(\"Vancouver buildings data - count split\")\n",
    "ax.legend(\n",
    "    handles=[Patch(facecolor=\"royalblue\"), Patch(facecolor=\"orange\")], labels=[\"Train\", \"Test\"]\n",
    ")\n",
    "cx.add_basemap(ax, source=cx.providers.CartoDB.PositronNoLabels, crs=4326, zoom=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## With numerical target column\n",
    "\n",
    "If a target column is provided, it will be automatically treated as a numerical column, split into buckets (default: `7`) and stratified based on those buckets. The value distibution will be roughly the same in both splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_height_gdf, test_height_gdf = train_test_spatial_split(\n",
    "    input_gdf=buildings,\n",
    "    parent_h3_resolution=9,\n",
    "    geometry_column=\"centroid\",\n",
    "    target_column=\"height\",\n",
    "    n_bins=7,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.kdeplot(\n",
    "    data=train_height_gdf,\n",
    "    x=\"height\",\n",
    "    fill=True,\n",
    "    label=\"train\",\n",
    "    log_scale=True,\n",
    ")\n",
    "sns.kdeplot(\n",
    "    data=test_height_gdf,\n",
    "    x=\"height\",\n",
    "    fill=True,\n",
    "    label=\"test\",\n",
    "    ax=ax,\n",
    ")\n",
    "ax.legend()\n",
    "ax.set_xlim(left=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_covering_h3_cells = h3_to_geoseries(\n",
    "    shapely_geometry_to_h3(train_height_gdf[\"centroid\"], H3_RESOLUTION)\n",
    ")\n",
    "test_covering_h3_cells = h3_to_geoseries(\n",
    "    shapely_geometry_to_h3(test_height_gdf[\"centroid\"], H3_RESOLUTION)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.rc_context({\"hatch.linewidth\": 0.3}):\n",
    "    ax = buildings.plot(\n",
    "        gpd.pd.qcut(buildings[\"height\"], 7),\n",
    "        figsize=(15, 15),\n",
    "        cmap=\"Spectral_r\",\n",
    "        legend=True,\n",
    "        legend_kwds=dict(title=\"Height category (m)\"),\n",
    "    )\n",
    "    train_covering_h3_cells.boundary.plot(color=\"black\", ax=ax, linewidth=0.3)\n",
    "    test_covering_h3_cells.plot(\n",
    "        ax=ax, linewidth=0.3, color=(0, 0, 0, 0), edgecolor=\"black\", hatch=\"//\"\n",
    "    )\n",
    "\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.get_yaxis().set_visible(False)\n",
    "    ax2.legend(\n",
    "        handles=[\n",
    "            Patch(edgecolor=\"black\", facecolor=(0, 0, 0, 0)),\n",
    "            Patch(edgecolor=\"black\", facecolor=(0, 0, 0, 0), hatch=\"///\"),\n",
    "        ],\n",
    "        labels=[\"Train\", \"Test\"],\n",
    "        loc=2,\n",
    "    )\n",
    "\n",
    "    ax.set_title(\"Vancouver buildings data - numerical split\")\n",
    "    cx.add_basemap(ax, source=cx.providers.CartoDB.PositronNoLabels, crs=4326, zoom=15, alpha=0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## With categorical target column\n",
    "\n",
    "Stratification can be also done based on the extisting categorical column, without using buckets.\n",
    "\n",
    "In that case, the `categorical` parameter must be set to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings[\"subtype\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_categorical_gdf, test_categorical_gdf = train_test_spatial_split(\n",
    "    input_gdf=buildings,\n",
    "    parent_h3_resolution=9,\n",
    "    geometry_column=\"centroid\",\n",
    "    target_column=\"subtype\",\n",
    "    categorical=True,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_categories_stats = train_categorical_gdf[\"subtype\"].value_counts().reset_index()\n",
    "train_categories_stats[\"count\"] /= train_categories_stats[\"count\"].sum()\n",
    "train_categories_stats[\"split\"] = \"train\"\n",
    "\n",
    "test_categories_stats = test_categorical_gdf[\"subtype\"].value_counts().reset_index()\n",
    "test_categories_stats[\"count\"] /= test_categories_stats[\"count\"].sum()\n",
    "test_categories_stats[\"split\"] = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(\n",
    "    data=gpd.pd.concat([train_categories_stats, test_categories_stats]),\n",
    "    x=\"count\",\n",
    "    y=\"subtype\",\n",
    "    hue=\"split\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_covering_h3_cells = h3_to_geoseries(\n",
    "    shapely_geometry_to_h3(train_categorical_gdf[\"centroid\"], H3_RESOLUTION)\n",
    ")\n",
    "test_covering_h3_cells = h3_to_geoseries(\n",
    "    shapely_geometry_to_h3(test_categorical_gdf[\"centroid\"], H3_RESOLUTION)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.rc_context({\"hatch.linewidth\": 0.3}):\n",
    "    ax = buildings.plot(\n",
    "        \"subtype\",\n",
    "        figsize=(15, 15),\n",
    "        cmap=\"Paired\",\n",
    "        legend=True,\n",
    "        legend_kwds=dict(title=\"Building subtype\"),\n",
    "    )\n",
    "    train_covering_h3_cells.boundary.plot(color=\"black\", ax=ax, linewidth=0.3)\n",
    "    test_covering_h3_cells.plot(\n",
    "        ax=ax, linewidth=0.3, color=(0, 0, 0, 0), edgecolor=\"black\", hatch=\"//\"\n",
    "    )\n",
    "\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.get_yaxis().set_visible(False)\n",
    "    ax2.legend(\n",
    "        handles=[\n",
    "            Patch(edgecolor=\"black\", facecolor=(0, 0, 0, 0)),\n",
    "            Patch(edgecolor=\"black\", facecolor=(0, 0, 0, 0), hatch=\"///\"),\n",
    "        ],\n",
    "        labels=[\"Train\", \"Test\"],\n",
    "        loc=2,\n",
    "    )\n",
    "\n",
    "    ax.set_title(\"Vancouver buildings data - categorical split\")\n",
    "    cx.add_basemap(ax, source=cx.providers.CartoDB.PositronNoLabels, crs=4326, zoom=15, alpha=0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## Splitting into three datasets at once\n",
    "\n",
    "By using another function, `spatial_split_points`, user can split the dataset into three groups at once (train, validation, test).\n",
    "\n",
    "Usually users want to split data into train and test sets, and run the splitting again to get the validation set, but `SRAI` exposes a function to split directly into 3 splits. This function returns a dictionary with splitted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = spatial_split_points(\n",
    "    input_gdf=buildings,\n",
    "    parent_h3_resolution=H3_RESOLUTION,\n",
    "    geometry_column=\"centroid\",\n",
    "    target_column=None,\n",
    "    # Can also be passed as an expected number of points, not only a fraction\n",
    "    test_size=1000,\n",
    "    validation_size=500,\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(splits.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = splits[\"train\"].plot(color=\"royalblue\", figsize=(15, 15), label=\"train\", legend=True)\n",
    "splits[\"test\"].plot(color=\"orange\", ax=ax, label=\"test\", legend=True)\n",
    "splits[\"validation\"].plot(color=\"limegreen\", ax=ax, label=\"validation\", legend=True)\n",
    "covering_h3_cells.boundary.plot(color=\"black\", ax=ax, linewidth=0.3)\n",
    "\n",
    "ax.set_title(\"Vancouver buildings data - count split into three sets\")\n",
    "ax.legend(\n",
    "    handles=[Patch(facecolor=\"royalblue\"), Patch(facecolor=\"orange\"), Patch(facecolor=\"limegreen\")],\n",
    "    labels=[\"Train\", \"Test\", \"Validation\"],\n",
    ")\n",
    "cx.add_basemap(ax, source=cx.providers.CartoDB.PositronNoLabels, crs=4326, zoom=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "### Parse split report manually\n",
    "\n",
    "You can use the `return_split_stats` to get the splitting report as a pandas DataFrame and manually validate splitting ratios.\n",
    "\n",
    "You can also use the `verbose` parameter to disable the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits, split_report = spatial_split_points(\n",
    "    input_gdf=buildings,\n",
    "    parent_h3_resolution=H3_RESOLUTION,\n",
    "    geometry_column=\"centroid\",\n",
    "    target_column=None,\n",
    "    # Can also be passed as an expected number of points, not only a fraction\n",
    "    test_size=1000,\n",
    "    validation_size=500,\n",
    "    random_state=42,\n",
    "    return_split_stats=True,\n",
    "    verbose=False,\n",
    ")\n",
    "split_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_report[[\"train_ratio\", \"validation_ratio\", \"test_ratio\"]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_report[\n",
    "    [\"train_ratio_difference\", \"validation_ratio_difference\", \"test_ratio_difference\"]\n",
    "].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_report[[\"train_points\", \"validation_points\", \"test_points\"]].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "## Different H3 resolutions\n",
    "\n",
    "You can perform splitting at different H3 resolutions, and the choice of resolution will affect the results.\n",
    "\n",
    "- Higher resolutions (smaller hexagons) produce a split ratio closer to your target, but the regions are physically closer together, which reduces true spatial separation.\n",
    "- Lower resolutions (larger hexagons) improve spatial separation but may cause the actual split ratio to deviate more from the target.\n",
    "\n",
    "As a rule of thumb, choose the lowest resolution that still keeps the split ratio difference within an acceptable range for your use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_per_resolution(resolution: int) -> None:\n",
    "    \"\"\"Split the data using given resolution.\"\"\"\n",
    "    test_ratio = 0.4\n",
    "    _train_gdf, _test_gdf = train_test_spatial_split(\n",
    "        input_gdf=buildings,\n",
    "        parent_h3_resolution=resolution,\n",
    "        geometry_column=\"centroid\",\n",
    "        target_column=\"height\",\n",
    "        test_size=test_ratio,\n",
    "        random_state=42,\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    actual_test_ratio = len(_test_gdf) / len(buildings)\n",
    "    test_ratio_diff = test_ratio - actual_test_ratio\n",
    "\n",
    "    _train_covering_h3_cells = h3_to_geoseries(\n",
    "        shapely_geometry_to_h3(_train_gdf[\"centroid\"], resolution)\n",
    "    )\n",
    "    _test_covering_h3_cells = h3_to_geoseries(\n",
    "        shapely_geometry_to_h3(_test_gdf[\"centroid\"], resolution)\n",
    "    )\n",
    "\n",
    "    with plt.rc_context({\"hatch.linewidth\": 0.3}):\n",
    "        ax = _train_gdf.plot(color=\"royalblue\", figsize=(15, 15))\n",
    "        _test_gdf.plot(color=\"orange\", ax=ax)\n",
    "        _train_covering_h3_cells.boundary.plot(color=\"black\", ax=ax, linewidth=0.3)\n",
    "        _test_covering_h3_cells.boundary.plot(color=\"black\", ax=ax, linewidth=0.3)\n",
    "\n",
    "        ax.legend(\n",
    "            handles=[Patch(facecolor=\"royalblue\"), Patch(facecolor=\"orange\")],\n",
    "            labels=[\"Train\", \"Test\"],\n",
    "        )\n",
    "\n",
    "        ax.set_title(\n",
    "            f\"Vancouver buildings data - numerical split (H3 resolution: {resolution})\\n\"\n",
    "            f\"Expected test ratio: {test_ratio:.2f}, Actual test ratio: {actual_test_ratio:.2f}, \"\n",
    "            f\"Diff: {test_ratio_diff:.3f}\"\n",
    "        )\n",
    "        cx.add_basemap(\n",
    "            ax, source=cx.providers.CartoDB.PositronNoLabels, crs=4326, zoom=15, alpha=0.5\n",
    "        )\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "for h3_res in range(7, 11):\n",
    "    split_per_resolution(h3_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "## What to do with timeseries data?\n",
    "\n",
    "TODO: add info about recommendation for working with timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "srai-3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
