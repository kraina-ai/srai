{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Spatial splitting with stratification\n",
    "\n",
    "SRAI library contains a dedicated functions for splitting the points dataset into train / test (and optionally validation) splits by separating the points spatially while also keeping them stratified based on a given target.\n",
    "\n",
    "The function only works for points dataset and uses [`H3`](https://h3geo.org/) indexing system to cluster points together and separate H3 cells into different splits.\n",
    "\n",
    "---\n",
    "\n",
    "When working with most machine learning datasets, splitting into training and testing sets is straightforward: pick a random subset for testing, and (optionally) use stratification to keep the distribution of a target variable balanced between the two. This works fine when the data points are independent.\n",
    "\n",
    "Geospatial data plays by different rules. Nearby locations often share similar characteristics - a phenomenon called spatial autocorrelation. If we split data randomly, our training and test sets might end up covering the same areas, meaning the model is “tested” on locations that are practically identical to ones it has already seen. This can make performance look much better than it really is and we can't test its capability to generalize the reasoning based on spatial features. \n",
    "\n",
    "That’s why for geo-related tasks, we need spatial splitting: making sure the training and test sets are separated in space so that evaluation reflects real-world conditions. Sometimes we also want to stratify these spatial splits by a numerical value to ensure both sets still have similar value distributions. Standard `train_test_split` functions can’t combine these two needs, so we provide a dedicated function for spatially aware splitting with optional stratification.\n",
    "\n",
    "---\n",
    "\n",
    "This notebook will show how different modes of splitting work based on buildings dataset from [Overture Maps Foundation](https://overturemaps.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "### How does it work?\n",
    "\n",
    "To separate the input dataset into multiple outputs, H3 indexing system is used to split groups of points together.\n",
    "\n",
    "First, the algorithm transform the points into H3 cells with a given resolution and calculates statistics per H3 cell (number of points per bucket / category).\n",
    "\n",
    "Next, all H3 cells are shuffled (with optional `random_state` to ensure reproducibility) and iterated one by one.\n",
    "\n",
    "For each split (test, validation, test) and each bucket per split, a current number of points is saved. While iterating each H3 cell with a group of points inside it, a potential new number of points is calculated with a difference to the expected ratio. Current H3 cell is assigned to the split where the difference to the expected ratio is the lowest.\n",
    "\n",
    "After iterating all H3 cells, the original dataset of points is split based on the list of assigned H3 cells.\n",
    "\n",
    "The report of splitting is printed with differences between expected and actual ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextily as cx\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import overturemaestro as om\n",
    "import pyarrow.compute as pc\n",
    "import seaborn as sns\n",
    "from matplotlib.axes import Axes\n",
    "from matplotlib.patches import Patch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from srai.h3 import h3_to_geoseries, shapely_geometry_to_h3\n",
    "from srai.spatial_split import spatial_split_points, train_test_spatial_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "Let's start with downloading example data. Here we will use Vancouver buildings from Overture Maps dataset.\n",
    "\n",
    "We only want buildings with both `height` and `subtype` columns filled.\n",
    "\n",
    "Height will be used in the numerical split example and subtype in the categorical split example.\n",
    "\n",
    "---\n",
    "\n",
    "Because the splitting only works on points, we will assign a centroid to each building as an additional column. Centroids will be calculated in the corresponding projected Coordinate Reference System."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "VANCOUVER_BOUNDING_BOX = (-123.148670, 49.255555, -123.076572, 49.296907)\n",
    "VANCOUVER_PROJECTED_CRS = 26910  # NAD83 / UTM zone 10N\n",
    "H3_RESOLUTION = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings = om.convert_bounding_box_to_geodataframe(\n",
    "    theme=\"buildings\",\n",
    "    type=\"building\",\n",
    "    bbox=VANCOUVER_BOUNDING_BOX,\n",
    "    pyarrow_filter=pc.field(\"subtype\").is_valid() & pc.field(\"height\").is_valid(),\n",
    "    columns_to_download=[\"subtype\", \"height\"],\n",
    ")\n",
    "buildings[\"centroid\"] = buildings.to_crs(VANCOUVER_PROJECTED_CRS).centroid.to_crs(4326)\n",
    "buildings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "First, let's see how the random split without spatial context looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split function from scikit-learn\n",
    "random_train_gdf, random_test_gdf = train_test_split(buildings, test_size=0.2, random_state=42)\n",
    "\n",
    "ax = random_train_gdf.plot(color=\"#1E88E5\", figsize=(15, 12), label=\"train\", legend=True)\n",
    "random_test_gdf.plot(color=\"#FFC107\", ax=ax, label=\"test\", legend=True)\n",
    "buildings.exterior.plot(ax=ax, color=\"black\", linewidth=0.3, alpha=0.5)\n",
    "\n",
    "ax.set_title(\"Vancouver buildings data - random split\")\n",
    "ax.legend(\n",
    "    handles=[Patch(facecolor=\"#1E88E5\"), Patch(facecolor=\"#FFC107\")],\n",
    "    labels=[\"Train\", \"Test\"],\n",
    ")\n",
    "cx.add_basemap(\n",
    "    ax,\n",
    "    source=cx.providers.CartoDB.VoyagerNoLabels,\n",
    "    crs=4326,\n",
    "    zoom=15,\n",
    "    alpha=0.8,\n",
    ")\n",
    "ax.set_axis_off()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "As shown, the buildings are split at random, resulting in both sets covering the same geographic area.\n",
    "\n",
    "With this approach, you can’t properly evaluate the model’s ability to generalize based on spatial patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Without target column - default\n",
    "\n",
    "Target column isn't required for spatial splitting.\n",
    "\n",
    "By default, the algorithm calculates a density of points per H3 cell and uses it for the for stratification. This way both splits have both dense and sparse regions in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_default_gdf, test_default_gdf = train_test_spatial_split(\n",
    "    input_gdf=buildings,\n",
    "    parent_h3_resolution=H3_RESOLUTION,\n",
    "    geometry_column=\"centroid\",\n",
    "    target_column=None,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")\n",
    "train_default_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "covering_h3_cells = h3_to_geoseries(shapely_geometry_to_h3(buildings[\"centroid\"], H3_RESOLUTION))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = train_default_gdf.plot(color=\"#1E88E5\", figsize=(15, 12), zorder=2)\n",
    "test_default_gdf.plot(color=\"#FFC107\", ax=ax, zorder=2)\n",
    "buildings.exterior.plot(ax=ax, color=\"black\", linewidth=0.3, alpha=0.5, zorder=2)\n",
    "covering_h3_cells.boundary.plot(color=\"black\", ax=ax, linewidth=0.3, alpha=0.5, zorder=1)\n",
    "\n",
    "ax.set_title(\"Vancouver buildings data - count split\")\n",
    "ax.legend(\n",
    "    handles=[Patch(facecolor=\"#1E88E5\"), Patch(facecolor=\"#FFC107\")],\n",
    "    labels=[\"Train\", \"Test\"],\n",
    ")\n",
    "cx.add_basemap(\n",
    "    ax,\n",
    "    source=cx.providers.CartoDB.VoyagerNoLabels,\n",
    "    crs=4326,\n",
    "    zoom=15,\n",
    "    alpha=0.8,\n",
    ")\n",
    "ax.set_axis_off()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## With numerical target column\n",
    "\n",
    "If a target column is provided, it will be automatically treated as a numerical column, split into buckets (default: `7`) and stratified based on those buckets. The value distibution will be roughly the same in both splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_height_gdf, test_height_gdf = train_test_spatial_split(\n",
    "    input_gdf=buildings,\n",
    "    parent_h3_resolution=9,\n",
    "    geometry_column=\"centroid\",\n",
    "    target_column=\"height\",\n",
    "    n_bins=7,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.kdeplot(\n",
    "    data=train_height_gdf,\n",
    "    x=\"height\",\n",
    "    fill=True,\n",
    "    label=\"train\",\n",
    "    log_scale=True,\n",
    ")\n",
    "sns.kdeplot(\n",
    "    data=test_height_gdf,\n",
    "    x=\"height\",\n",
    "    fill=True,\n",
    "    label=\"test\",\n",
    "    ax=ax,\n",
    ")\n",
    "ax.legend()\n",
    "ax.set_xlim(left=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_covering_h3_cells = h3_to_geoseries(\n",
    "    shapely_geometry_to_h3(train_height_gdf[\"centroid\"], H3_RESOLUTION)\n",
    ")\n",
    "test_covering_h3_cells = h3_to_geoseries(\n",
    "    shapely_geometry_to_h3(test_height_gdf[\"centroid\"], H3_RESOLUTION)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.rc_context({\"hatch.linewidth\": 0.3}):\n",
    "    ax = buildings.plot(\n",
    "        gpd.pd.qcut(buildings[\"height\"], 7),\n",
    "        figsize=(15, 12),\n",
    "        cmap=\"Spectral_r\",\n",
    "        legend=True,\n",
    "        legend_kwds=dict(title=\"Height category (m)\"),\n",
    "        zorder=2,\n",
    "    )\n",
    "    buildings.exterior.plot(ax=ax, color=\"black\", linewidth=0.3, zorder=2, alpha=0.5)\n",
    "    train_covering_h3_cells.boundary.plot(color=\"black\", ax=ax, linewidth=0.3, zorder=1)\n",
    "    test_covering_h3_cells.plot(\n",
    "        ax=ax,\n",
    "        linewidth=0.3,\n",
    "        color=(0, 0, 0, 0),\n",
    "        edgecolor=\"black\",\n",
    "        hatch=\"//\",\n",
    "        zorder=1,\n",
    "    )\n",
    "\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.get_yaxis().set_visible(False)\n",
    "    ax2.legend(\n",
    "        handles=[\n",
    "            Patch(edgecolor=\"black\", facecolor=(0, 0, 0, 0)),\n",
    "            Patch(edgecolor=\"black\", facecolor=(0, 0, 0, 0), hatch=\"///\"),\n",
    "        ],\n",
    "        labels=[\"Train\", \"Test\"],\n",
    "        loc=2,\n",
    "    )\n",
    "\n",
    "    ax.set_title(\"Vancouver buildings data - numerical split\")\n",
    "    cx.add_basemap(\n",
    "        ax,\n",
    "        source=cx.providers.CartoDB.VoyagerNoLabels,\n",
    "        crs=4326,\n",
    "        zoom=15,\n",
    "        alpha=0.5,\n",
    "    )\n",
    "    ax.set_axis_off()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## With categorical target column\n",
    "\n",
    "Stratification can be also done based on the extisting categorical column, without using buckets.\n",
    "\n",
    "In that case, the `categorical` parameter must be set to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings[\"subtype\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_categorical_gdf, test_categorical_gdf = train_test_spatial_split(\n",
    "    input_gdf=buildings,\n",
    "    parent_h3_resolution=9,\n",
    "    geometry_column=\"centroid\",\n",
    "    target_column=\"subtype\",\n",
    "    categorical=True,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_categories_stats = train_categorical_gdf[\"subtype\"].value_counts().reset_index()\n",
    "train_categories_stats[\"count\"] /= train_categories_stats[\"count\"].sum()\n",
    "train_categories_stats[\"split\"] = \"train\"\n",
    "\n",
    "test_categories_stats = test_categorical_gdf[\"subtype\"].value_counts().reset_index()\n",
    "test_categories_stats[\"count\"] /= test_categories_stats[\"count\"].sum()\n",
    "test_categories_stats[\"split\"] = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(\n",
    "    data=gpd.pd.concat([train_categories_stats, test_categories_stats]),\n",
    "    x=\"count\",\n",
    "    y=\"subtype\",\n",
    "    hue=\"split\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_covering_h3_cells = h3_to_geoseries(\n",
    "    shapely_geometry_to_h3(train_categorical_gdf[\"centroid\"], H3_RESOLUTION)\n",
    ")\n",
    "test_covering_h3_cells = h3_to_geoseries(\n",
    "    shapely_geometry_to_h3(test_categorical_gdf[\"centroid\"], H3_RESOLUTION)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.rc_context({\"hatch.linewidth\": 0.3}):\n",
    "    ax = buildings.plot(\n",
    "        \"subtype\",\n",
    "        categories=buildings[\"subtype\"].value_counts().index,\n",
    "        figsize=(15, 12),\n",
    "        cmap=\"Set3\",\n",
    "        legend=True,\n",
    "        legend_kwds=dict(title=\"Building subtype\"),\n",
    "        zorder=2,\n",
    "    )\n",
    "    buildings.exterior.plot(ax=ax, color=\"black\", linewidth=0.3, zorder=2, alpha=0.5)\n",
    "    train_covering_h3_cells.boundary.plot(color=\"black\", ax=ax, linewidth=0.3, zorder=1)\n",
    "    test_covering_h3_cells.plot(\n",
    "        ax=ax,\n",
    "        linewidth=0.3,\n",
    "        color=(0, 0, 0, 0),\n",
    "        edgecolor=\"black\",\n",
    "        hatch=\"//\",\n",
    "        zorder=1,\n",
    "    )\n",
    "\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.get_yaxis().set_visible(False)\n",
    "    ax2.legend(\n",
    "        handles=[\n",
    "            Patch(edgecolor=\"black\", facecolor=(0, 0, 0, 0)),\n",
    "            Patch(edgecolor=\"black\", facecolor=(0, 0, 0, 0), hatch=\"///\"),\n",
    "        ],\n",
    "        labels=[\"Train\", \"Test\"],\n",
    "        loc=2,\n",
    "    )\n",
    "\n",
    "    ax.set_title(\"Vancouver buildings data - categorical split\")\n",
    "    cx.add_basemap(\n",
    "        ax,\n",
    "        source=cx.providers.CartoDB.VoyagerNoLabels,\n",
    "        crs=4326,\n",
    "        zoom=15,\n",
    "        alpha=0.5,\n",
    "    )\n",
    "    ax.set_axis_off()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "## Splitting into three datasets at once\n",
    "\n",
    "By using another function, `spatial_split_points`, user can split the dataset into three groups at once (train, validation, test).\n",
    "\n",
    "Usually users want to split data into train and test sets, and run the splitting again to get the validation set, but `SRAI` exposes a function to split directly into 3 splits. This function returns a dictionary with splitted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = spatial_split_points(\n",
    "    input_gdf=buildings,\n",
    "    parent_h3_resolution=H3_RESOLUTION,\n",
    "    geometry_column=\"centroid\",\n",
    "    target_column=None,\n",
    "    # Size can also be passed as an expected number of points, not only a fraction\n",
    "    test_size=1000,\n",
    "    validation_size=500,\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(splits.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = splits[\"train\"].plot(color=\"#1E88E5\", figsize=(15, 12), zorder=2)\n",
    "splits[\"test\"].plot(color=\"#FFC107\", ax=ax, zorder=2)\n",
    "splits[\"validation\"].plot(color=\"#D81B60\", ax=ax, zorder=2)\n",
    "buildings.exterior.plot(ax=ax, color=\"black\", linewidth=0.3, alpha=0.5, zorder=2)\n",
    "covering_h3_cells.boundary.plot(color=\"black\", ax=ax, linewidth=0.3, alpha=0.5, zorder=1)\n",
    "\n",
    "ax.set_title(\"Vancouver buildings data - count split into three sets\")\n",
    "ax.legend(\n",
    "    handles=[\n",
    "        Patch(facecolor=\"#1E88E5\"),\n",
    "        Patch(facecolor=\"#FFC107\"),\n",
    "        Patch(facecolor=\"#D81B60\"),\n",
    "    ],\n",
    "    labels=[\"Train\", \"Test\", \"Validation\"],\n",
    ")\n",
    "cx.add_basemap(\n",
    "    ax,\n",
    "    source=cx.providers.CartoDB.VoyagerNoLabels,\n",
    "    crs=4326,\n",
    "    zoom=15,\n",
    "    alpha=0.8,\n",
    ")\n",
    "ax.set_axis_off()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "### Parse split report manually\n",
    "\n",
    "You can use the `return_split_stats` to get the splitting report as a pandas DataFrame and manually validate splitting ratios.\n",
    "\n",
    "You can also use the `verbose` parameter to disable the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits, split_report = spatial_split_points(\n",
    "    input_gdf=buildings,\n",
    "    parent_h3_resolution=H3_RESOLUTION,\n",
    "    geometry_column=\"centroid\",\n",
    "    target_column=None,\n",
    "    # Can also be passed as an expected number of points, not only a fraction\n",
    "    test_size=1000,\n",
    "    validation_size=500,\n",
    "    random_state=42,\n",
    "    return_split_stats=True,\n",
    "    verbose=False,\n",
    ")\n",
    "split_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_report[[\"train_ratio\", \"validation_ratio\", \"test_ratio\"]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_report[\n",
    "    [\n",
    "        \"train_ratio_difference\",\n",
    "        \"validation_ratio_difference\",\n",
    "        \"test_ratio_difference\",\n",
    "    ]\n",
    "].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_report[[\"train_points\", \"validation_points\", \"test_points\"]].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "## Different H3 resolutions\n",
    "\n",
    "You can perform splitting at different H3 resolutions, and the choice of resolution will affect the results.\n",
    "\n",
    "- Higher resolutions (smaller hexagons) produce a split ratio closer to your target, but the regions are physically closer together, which reduces true spatial separation.\n",
    "- Lower resolutions (larger hexagons) improve spatial separation but may cause the actual split ratio to deviate more from the target.\n",
    "\n",
    "<div class=\"admonition tip\">\n",
    "    <p class=\"admonition-title\">Selecting proper H3 resolution</p>\n",
    "    <p>\n",
    "    As a rule of thumb, choose the lowest resolution that still keeps the split ratio difference within an acceptable range for your use case.\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_per_resolution(resolution: int, ax: Axes, h3_edge_alpha: float) -> None:\n",
    "    \"\"\"Split the data using given resolution.\"\"\"\n",
    "    test_ratio = 0.4\n",
    "    _train_gdf, _test_gdf = train_test_spatial_split(\n",
    "        input_gdf=buildings,\n",
    "        parent_h3_resolution=resolution,\n",
    "        geometry_column=\"centroid\",\n",
    "        target_column=\"height\",\n",
    "        test_size=test_ratio,\n",
    "        random_state=42,\n",
    "        verbose=False,\n",
    "    )\n",
    "    buildings.exterior.plot(ax=ax, color=\"black\", linewidth=0.3, alpha=0.5, zorder=2)\n",
    "\n",
    "    actual_test_ratio = len(_test_gdf) / len(buildings)\n",
    "    test_ratio_diff = test_ratio - actual_test_ratio\n",
    "\n",
    "    _train_covering_h3_cells = h3_to_geoseries(\n",
    "        shapely_geometry_to_h3(_train_gdf[\"centroid\"], resolution)\n",
    "    )\n",
    "    _test_covering_h3_cells = h3_to_geoseries(\n",
    "        shapely_geometry_to_h3(_test_gdf[\"centroid\"], resolution)\n",
    "    )\n",
    "\n",
    "    _train_gdf.plot(color=\"#1E88E5\", ax=ax, zorder=2)\n",
    "    _test_gdf.plot(color=\"#FFC107\", ax=ax, zorder=2)\n",
    "    _train_covering_h3_cells.boundary.plot(\n",
    "        color=\"black\", ax=ax, linewidth=0.3, alpha=h3_edge_alpha, zorder=1\n",
    "    )\n",
    "    _test_covering_h3_cells.boundary.plot(\n",
    "        color=\"black\", ax=ax, linewidth=0.3, alpha=h3_edge_alpha, zorder=1\n",
    "    )\n",
    "\n",
    "    ax.legend(\n",
    "        handles=[Patch(facecolor=\"#1E88E5\"), Patch(facecolor=\"#FFC107\")],\n",
    "        labels=[\"Train\", \"Test\"],\n",
    "    )\n",
    "\n",
    "    ax.set_title(\n",
    "        f\"Vancouver buildings data - numerical split (H3 resolution: {resolution})\\n\"\n",
    "        f\"Expected test ratio: {test_ratio:.2f}, \"\n",
    "        f\"Actual test ratio: {actual_test_ratio:.2f}, \"\n",
    "        f\"Diff: {test_ratio_diff:.3f}\"\n",
    "    )\n",
    "    cx.add_basemap(\n",
    "        ax,\n",
    "        source=cx.providers.CartoDB.VoyagerNoLabels,\n",
    "        crs=4326,\n",
    "        zoom=15,\n",
    "        alpha=0.8,\n",
    "    )\n",
    "    ax.set_axis_off()\n",
    "\n",
    "\n",
    "with plt.rc_context({\"hatch.linewidth\": 0.3}):\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(20, 18), sharex=True, sharey=True)\n",
    "    pairs = [\n",
    "        (7, axes[0][0], 1.0),\n",
    "        (8, axes[0][1], 0.9),\n",
    "        (9, axes[1][0], 0.8),\n",
    "        (10, axes[1][1], 0.7),\n",
    "    ]\n",
    "    for h3_res, ax, h3_edge_alpha in pairs:\n",
    "        split_per_resolution(h3_res, ax, h3_edge_alpha)\n",
    "\n",
    "buildings_bounds = buildings.total_bounds\n",
    "for ax in axes.flatten():\n",
    "    ax.set_xlim(buildings_bounds[0] - 0.001, buildings_bounds[2] + 0.001)\n",
    "    ax.set_ylim(buildings_bounds[1] - 0.001, buildings_bounds[3] + 0.001)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "## What to do with timeseries data?\n",
    "\n",
    "When working with geospatial datasets that include a time component — for example, store locations with monthly performance data over the past year — it’s important to consider how the split is performed.\n",
    "\n",
    "If you split purely at the row level, the same store might appear in both training and test sets for different months. This creates data leakage: the model could learn store-specific patterns from the training set and then see almost the same data in the test set, inflating performance metrics.\n",
    "\n",
    "A better approach is to **split at the entity level**. For stores, that means assigning each store to a single split (train or test) and including all its historical monthly records in that split. This ensures that the model is evaluated on entirely unseen stores, which is especially important when the goal is to build a whitespot model for identifying promising new locations.\n",
    "\n",
    "<div class=\"admonition tip\">\n",
    "    <p class=\"admonition-title\">Utilizing temporal component</p>\n",
    "    <p>\n",
    "    If your dataset is big enough (data from multiple years), you can combine spatial splitting with temporal splitting to test how the model generalizes to both unseen stores and future time periods.\n",
    "    </p>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "Example below will show you how to utilize monthly transaction data to split the locations for the whitespot analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "First, let's select only the commercial buildings from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "stores = buildings[buildings[\"subtype\"] == \"commercial\"].copy()\n",
    "stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = stores.plot(figsize=(15, 15))\n",
    "cx.add_basemap(\n",
    "    ax,\n",
    "    source=cx.providers.CartoDB.VoyagerNoLabels,\n",
    "    crs=4326,\n",
    "    zoom=15,\n",
    "    alpha=0.8,\n",
    ")\n",
    "ax.set_axis_off()\n",
    "ax.set_title(\"Vancouver - commercial buildings\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "Now, we can generate the dummy monthly sales data for the last year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def generate_monthly_sales(store_ids: pd.Index, seed=None):\n",
    "    \"\"\"\n",
    "    Generate dummy monthly sales data for the past 12 months.\n",
    "\n",
    "    Args:\n",
    "        store_ids (pd.Index): IDs of locations.\n",
    "        seed (int, optional): Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Columns = ['location_id', 'month', 'sales']\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed=seed)\n",
    "\n",
    "    # Generate month labels (last 12 months, newest last)\n",
    "    months = pd.date_range(end=pd.Timestamp.today(), periods=12, freq=\"M\")\n",
    "    month_labels = months.strftime(\"%Y-%m\").tolist()\n",
    "\n",
    "    # Seasonal multiplier with peak at December (sinusoidal pattern)\n",
    "    phases = 2 * np.pi * (months.month - 12) / 12.0\n",
    "    seasonal_factor = 1.0 + 0.2 * np.cos(phases)\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for loc_id in store_ids:\n",
    "        # Start with a base sales value for this location\n",
    "        base_sales = rng.integers(8000, 20000)\n",
    "\n",
    "        # Create gradual monthly changes using a small random walk\n",
    "        gradual_changes = np.cumsum(rng.normal(loc=0, scale=300, size=12))\n",
    "\n",
    "        # Combine base + changes + seasonality\n",
    "        sales = (base_sales + gradual_changes) * seasonal_factor\n",
    "\n",
    "        # Ensure sales are positive\n",
    "        sales = np.clip(sales, 0, None)\n",
    "\n",
    "        # Append to dataset\n",
    "        for month_str, value in zip(month_labels, sales):\n",
    "            data.append((loc_id, month_str, round(value, 2)))\n",
    "\n",
    "    df = pd.DataFrame(data, columns=[\"id\", \"month\", \"sales\"]).set_index(\"id\")\n",
    "    return df\n",
    "\n",
    "\n",
    "df_sales = generate_monthly_sales(store_ids=stores.index, seed=42)\n",
    "df_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "sns.lineplot(df_sales, x=\"month\", y=\"sales\", hue=\"id\", legend=False, alpha=0.4, ax=ax)\n",
    "ax.set_title(\"Monthly sales data per store\")\n",
    "ax.set_ylabel(\"Sales\")\n",
    "ax.set_xlabel(\"Month\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "Now that we have stores locations and a dataframe with monthly sales data per location, we will calculate the average number of sales per month and use this information to stratify the spatial split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_monthly_sales = df_sales.groupby(\"id\")[\"sales\"].mean()  # You can also use median\n",
    "sns.histplot(mean_monthly_sales, kde=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "Now we have to assign the mean values to the original dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "stores[\"mean_monthly_sales\"] = mean_monthly_sales\n",
    "stores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "Let's do the spit based on the mean monthly sales. We will reduce the number of bins to decrease the actual ratio difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sales_gdf, test_sales_gdf = train_test_spatial_split(\n",
    "    input_gdf=stores,\n",
    "    parent_h3_resolution=8,\n",
    "    geometry_column=\"centroid\",\n",
    "    target_column=\"mean_monthly_sales\",\n",
    "    n_bins=5,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "Here is the distribution between two sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.kdeplot(\n",
    "    data=train_sales_gdf,\n",
    "    x=\"mean_monthly_sales\",\n",
    "    fill=True,\n",
    "    label=\"train\",\n",
    ")\n",
    "sns.kdeplot(\n",
    "    data=test_sales_gdf,\n",
    "    x=\"mean_monthly_sales\",\n",
    "    fill=True,\n",
    "    label=\"test\",\n",
    "    ax=ax,\n",
    ")\n",
    "ax.legend()\n",
    "ax.set_title(\"Mean monthly sales distribution per split\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_covering_h3_cells = h3_to_geoseries(shapely_geometry_to_h3(train_sales_gdf[\"centroid\"], 8))\n",
    "test_covering_h3_cells = h3_to_geoseries(shapely_geometry_to_h3(test_sales_gdf[\"centroid\"], 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.rc_context({\"hatch.linewidth\": 0.3}):\n",
    "    ax = stores.plot(\n",
    "        # gpd.pd.qcut(buildings[\"height\"], 7),\n",
    "        \"mean_monthly_sales\",\n",
    "        figsize=(15, 10),\n",
    "        # cmap=\"Spectral_r\",\n",
    "        cmap=\"RdYlBu_r\",\n",
    "        legend=True,\n",
    "        legend_kwds=dict(\n",
    "            shrink=0.9,\n",
    "            orientation=\"horizontal\",\n",
    "            pad=0.01,\n",
    "            label=\"Mean monthly sales\",\n",
    "            aspect=60,\n",
    "            fraction=0.03,\n",
    "        ),\n",
    "        zorder=2,\n",
    "    )\n",
    "    stores.exterior.plot(ax=ax, color=\"black\", linewidth=0.3, zorder=2)\n",
    "    train_covering_h3_cells.boundary.plot(color=\"black\", ax=ax, linewidth=0.3, zorder=1)\n",
    "    test_covering_h3_cells.plot(\n",
    "        ax=ax,\n",
    "        linewidth=0.3,\n",
    "        color=(0, 0, 0, 0),\n",
    "        edgecolor=\"black\",\n",
    "        hatch=\"/\",\n",
    "        zorder=1,\n",
    "    )\n",
    "\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.get_yaxis().set_visible(False)\n",
    "    ax2.legend(\n",
    "        handles=[\n",
    "            Patch(edgecolor=\"black\", facecolor=(0, 0, 0, 0)),\n",
    "            Patch(edgecolor=\"black\", facecolor=(0, 0, 0, 0), hatch=\"///\"),\n",
    "        ],\n",
    "        labels=[\"Train\", \"Test\"],\n",
    "        loc=2,\n",
    "    )\n",
    "\n",
    "    ax.set_title(\"Vancouver - commercial buildings - sales numerical split\")\n",
    "    cx.add_basemap(\n",
    "        ax,\n",
    "        source=cx.providers.CartoDB.VoyagerNoLabels,\n",
    "        crs=4326,\n",
    "        zoom=15,\n",
    "        alpha=0.8,\n",
    "    )\n",
    "    ax.set_axis_off()\n",
    "    stores_bounds = stores.total_bounds\n",
    "    ax.set_xlim(stores_bounds[0] - 0.01, stores_bounds[2] + 0.01)\n",
    "    ax.set_ylim(stores_bounds[1] - 0.01, stores_bounds[3] + 0.01)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {},
   "source": [
    "Now we can select transaction data based on location IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_store_sales = df_sales.loc[train_sales_gdf.index]\n",
    "test_store_sales = df_sales.loc[test_sales_gdf.index]\n",
    "\n",
    "print(len(train_store_sales), len(test_store_sales))\n",
    "train_store_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "sns.lineplot(train_store_sales, x=\"month\", y=\"sales\", legend=True, ax=ax, label=\"train\")\n",
    "sns.lineplot(test_store_sales, x=\"month\", y=\"sales\", legend=True, ax=ax, label=\"test\")\n",
    "\n",
    "ax.set_title(\"Monthly sales data per store\")\n",
    "ax.set_ylabel(\"Sales\")\n",
    "ax.set_xlabel(\"Month\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.kdeplot(\n",
    "    data=train_store_sales,\n",
    "    x=\"sales\",\n",
    "    fill=True,\n",
    "    label=\"train\",\n",
    ")\n",
    "sns.kdeplot(\n",
    "    data=test_store_sales,\n",
    "    x=\"sales\",\n",
    "    fill=True,\n",
    "    label=\"test\",\n",
    "    ax=ax,\n",
    ")\n",
    "ax.legend()\n",
    "ax.set_title(\"Sales distribution per split\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "srai-3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
