{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import contextily as cx\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "from pytorch_lightning import seed_everything\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from srai.embedders import S2VecEmbedder\n",
    "from srai.embedders.s2vec.s2_utils import get_patches_from_img_gdf\n",
    "from srai.loaders import OSMPbfLoader\n",
    "from srai.loaders.osm_loaders.filters import GEOFABRIK_LAYERS\n",
    "from srai.plotting import plot_regions\n",
    "from srai.regionalizers import S2Regionalizer, geocode_to_region_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 71\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### Load data from OSM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "First use geocoding to get the area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "area_gdf = geocode_to_region_gdf(\"Wroc≈Çaw, Poland\")\n",
    "plot_regions(area_gdf, tiles_style=\"CartoDB positron\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_resolution = 12\n",
    "patch_resolution = 16\n",
    "\n",
    "img_regionalizer = S2Regionalizer(resolution=img_resolution, buffer=True)\n",
    "img_s2_regions = img_regionalizer.transform(area_gdf.reset_index(drop=True))\n",
    "\n",
    "img_s2_geometry = img_s2_regions.union_all()\n",
    "\n",
    "print(\"Image regions:\", len(img_s2_regions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### Download the Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "Next, download the data for the selected region and the specified tags.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = GEOFABRIK_LAYERS\n",
    "loader = OSMPbfLoader()\n",
    "\n",
    "features_gdf = loader.load(img_s2_regions, tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Prepare the data for embedding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "After downloading the data, we need to prepare it for embedding. In the previous step we have regionalized the selected area and buffered it, now we have to join the features with prepared regions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_regions(img_s2_regions, tiles_style=\"CartoDB positron\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## S2Vec Embedding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "After preparing the data we can proceed with generating embeddings for the regions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = S2VecEmbedder(\n",
    "    target_features=GEOFABRIK_LAYERS,\n",
    "    batch_size=8,\n",
    "    img_res=img_resolution,\n",
    "    patch_res=patch_resolution,\n",
    "    embedding_dim=64,\n",
    "    decoder_dim=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "    csv_logger = CSVLogger(save_dir=\"s2vec_logs\")\n",
    "\n",
    "    embeddings = embedder.fit_transform(\n",
    "        regions_gdf=img_s2_regions,\n",
    "        features_gdf=features_gdf,\n",
    "        trainer_kwargs={\n",
    "            # \"max_epochs\": 20, # uncomment for a longer training\n",
    "            \"max_epochs\": 5,\n",
    "            \"accelerator\": (\"cpu\" if torch.backends.mps.is_available() else \"auto\"),\n",
    "            \"logger\": csv_logger,\n",
    "        },\n",
    "        learning_rate=0.001,\n",
    "    )\n",
    "\n",
    "embeddings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.read_csv(csv_logger.log_dir + \"/metrics.csv\").dropna(\n",
    "    subset=\"train_loss_epoch\"\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "\n",
    "line1 = ax.plot(metrics_df[\"epoch\"], metrics_df[\"train_loss_epoch\"])\n",
    "ax.set_title(\"Training metrics\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_s2_regions, _ = get_patches_from_img_gdf(\n",
    "    img_s2_regions, target_level=patch_resolution\n",
    ")\n",
    "\n",
    "# do pca with three components and then cast to RGB\n",
    "pca = PCA(n_components=3)\n",
    "\n",
    "pca_embeddings = pca.fit_transform(embeddings)\n",
    "# make the embeddings into a dataframe\n",
    "pca_embeddings = pd.DataFrame(pca_embeddings, index=embeddings.index)\n",
    "\n",
    "# convert to RGB\n",
    "pca_embeddings = (\n",
    "    (pca_embeddings - pca_embeddings.min())\n",
    "    / (pca_embeddings.max() - pca_embeddings.min())\n",
    ").astype(float)\n",
    "pca_embeddings[\"rgb\"] = pca_embeddings.apply(\n",
    "    lambda row: (row[0], row[1], row[2]), axis=1\n",
    ")\n",
    "color_values = patch_s2_regions.index.map(pca_embeddings[\"rgb\"].to_dict()).to_list()\n",
    "\n",
    "ax = (\n",
    "    patch_s2_regions.reset_index()\n",
    "    .reset_index()\n",
    "    .plot(color=color_values, antialiased=True, figsize=(20, 20), alpha=0.6)\n",
    ")\n",
    "cx.add_basemap(ax, source=cx.providers.CartoDB.PositronNoLabels, crs=4326, zoom=12)\n",
    "ax.set_axis_off()\n",
    "ax.set_title(\"PCA representaion of embeddings\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "### Clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterizer = KMeans(n_clusters=5, random_state=SEED)\n",
    "clusterizer.fit(embeddings)\n",
    "embeddings.index.name = \"region_id\"\n",
    "embeddings[\"cluster\"] = clusterizer.labels_\n",
    "embeddings[\"cluster\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = patch_s2_regions.plot(\n",
    "    embeddings[\"cluster\"],\n",
    "    antialiased=True,\n",
    "    figsize=(20, 20),\n",
    "    alpha=0.6,\n",
    "    legend=True,\n",
    "    cmap=\"Spectral\",\n",
    "    categorical=True,\n",
    ")\n",
    "cx.add_basemap(ax, source=cx.providers.CartoDB.PositronNoLabels, crs=4326, zoom=12)\n",
    "ax.set_axis_off()\n",
    "ax.set_title(\"Clustering result\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "srai-3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
