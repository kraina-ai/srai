{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from srai.embedders import GeoVexEmbedder, CountEmbedder\n",
    "from srai.joiners import IntersectionJoiner\n",
    "from srai.loaders import OSMPbfLoader\n",
    "from srai.neighbourhoods import H3Neighbourhood\n",
    "from srai.regionalizers import H3Regionalizer, geocode_to_region_gdf\n",
    "from srai.plotting import plot_regions, plot_numeric_data\n",
    "from pytorch_lightning import seed_everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 71\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data from OSM\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First use geocoding to get the area\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_gdf = geocode_to_region_gdf(\"Greater London, UK\")\n",
    "plot_regions(area_gdf, tiles_style=\"CartoDB positron\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buffer the Area\n",
    "\n",
    "The GeoVex embedder requires a buffer around the area of interest, as the hexagon needs to have its radius k neighbors in the dataset as well.\n",
    "The buffer is defined in hexagon radius units, so a buffer of 1 means that the hexagon will have its 1-neighborhood in the dataset as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from srai.h3 import ring_buffer_h3_regions_gdf\n",
    "\n",
    "resolution = 9\n",
    "k_ring_buffer_radius = 4\n",
    "\n",
    "regionalizer = H3Regionalizer(resolution=resolution)\n",
    "base_h3_regions = regionalizer.transform(area_gdf)\n",
    "\n",
    "buffered_h3_regions = ring_buffer_h3_regions_gdf(base_h3_regions, distance=k_ring_buffer_radius)\n",
    "buffered_h3_geometry = buffered_h3_regions.unary_union\n",
    "\n",
    "print(\"Base regions:\", len(base_h3_regions))\n",
    "print(\"Buffered regions:\", len(buffered_h3_regions))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the Data\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, download the data for the selected region and the specified tags. We're using `OSMOnlineLoader` here, as it's faster for low numbers of tags.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from srai.loaders.osm_loaders.filters import HEX2VEC_FILTER\n",
    "\n",
    "tags = HEX2VEC_FILTER\n",
    "loader = OSMPbfLoader()\n",
    "\n",
    "features_gdf = loader.load(buffered_h3_geometry, tags)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data for embedding\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After downloading the data, we need to prepare it for embedding. In the previous step we have regionalized the selected area and buffered it, now we have to join the features with prepared regions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_regions(buffered_h3_regions, tiles_style=\"CartoDB positron\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joiner = IntersectionJoiner()\n",
    "joint_gdf = joiner.transform(buffered_h3_regions, features_gdf)\n",
    "joint_gdf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GeoVex-Embedding\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After preparing the data we can proceed with generating embeddings for the regions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "neighbourhood = H3Neighbourhood(buffered_h3_regions)\n",
    "\n",
    "embedder = GeoVexEmbedder(\n",
    "    target_features=[f\"{super_}_{sub}\" for super_, subs in HEX2VEC_FILTER.items() for sub in subs],\n",
    "    neighbourhood=neighbourhood,\n",
    "    batch_size=8,\n",
    "    neighbourhood_radius=k_ring_buffer_radius,\n",
    "    convolutional_layers=2,\n",
    "    embedding_size=50,\n",
    ")\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "    embeddings = embedder.fit_transform(\n",
    "        regions_gdf=buffered_h3_regions,\n",
    "        features_gdf=features_gdf,\n",
    "        joint_gdf=joint_gdf,\n",
    "        neighbourhood=neighbourhood,\n",
    "        trainer_kwargs={\n",
    "            # \"max_epochs\": 20, # uncomment for a longer training\n",
    "            \"max_epochs\": 2,\n",
    "            \"accelerator\": \"cpu\",\n",
    "        },\n",
    "        learning_rate=0.001,\n",
    "    )\n",
    "\n",
    "embeddings.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hex2Vec Embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from srai.embedders import Hex2VecEmbedder\n",
    "import warnings\n",
    "\n",
    "neighbourhood = H3Neighbourhood(buffered_h3_regions)\n",
    "\n",
    "hex2vec_embedder = Hex2VecEmbedder(\n",
    "    encoder_sizes=[300, 150, 50],\n",
    ")\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "    hex2vec_embeddings = hex2vec_embedder.fit_transform(\n",
    "        regions_gdf=buffered_h3_regions,\n",
    "        features_gdf=features_gdf,\n",
    "        joint_gdf=joint_gdf,\n",
    "        neighbourhood=neighbourhood,\n",
    "        negative_sample_k_distance=2,\n",
    "        batch_size=64,\n",
    "        learning_rate=0.001,\n",
    "        trainer_kwargs={\n",
    "            # \"max_epochs\": 50, # uncomment for a longer training\n",
    "            \"max_epochs\": 5,\n",
    "            \"accelerator\": \"cpu\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "hex2vec_embeddings.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the Embeddings\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GeoVex Embedding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do pca with three components and then cast to RGB\n",
    "from sklearn.decomposition import PCA\n",
    "from srai.plotting import plot_numeric_data\n",
    "import pandas as pd\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "\n",
    "pca_embeddings = pca.fit_transform(embeddings)\n",
    "# make the embeddings into a dataframe\n",
    "pca_embeddings = pd.DataFrame(pca_embeddings, index=embeddings.index)\n",
    "\n",
    "# convert to RGB\n",
    "pca_embeddings = (\n",
    "    (pca_embeddings - pca_embeddings.min()) / (pca_embeddings.max() - pca_embeddings.min()) * 255\n",
    ").astype(int)\n",
    "\n",
    "# make the rgb array into a string\n",
    "pca_embeddings[\"rgb\"] = pca_embeddings.apply(\n",
    "    lambda row: f\"rgb({row[0]}, {row[1]}, {row[2]})\", axis=1\n",
    ")\n",
    "\n",
    "\n",
    "color_dict = dict(\n",
    "    enumerate(buffered_h3_regions.index.map(pca_embeddings[\"rgb\"].to_dict()).to_list())\n",
    ")\n",
    "buffered_h3_regions.reset_index().reset_index().explore(\n",
    "    column=\"index\",\n",
    "    tooltip=\"region_id\",\n",
    "    tiles=\"CartoDB positron\",\n",
    "    legend=False,\n",
    "    cmap=lambda x: color_dict[x],\n",
    "    style_kwds=dict(color=\"#444\", opacity=0.0, fillOpacity=0.5),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "clusterizer = KMeans(n_clusters=5, random_state=SEED)\n",
    "clusterizer.fit(embeddings)\n",
    "embeddings.index.name = \"region_id\"\n",
    "embeddings[\"cluster\"] = clusterizer.labels_\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_numeric_data(buffered_h3_regions, \"cluster\", embeddings, tiles_style=\"CartoDB positron\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hex2Vec\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do pca with three components and then cast to RGB\n",
    "from sklearn.decomposition import PCA\n",
    "from srai.plotting import plot_numeric_data\n",
    "import pandas as pd\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "\n",
    "pca_embeddings = pca.fit_transform(hex2vec_embeddings)\n",
    "# make the embeddings into a dataframe\n",
    "pca_embeddings = pd.DataFrame(pca_embeddings, index=hex2vec_embeddings.index)\n",
    "\n",
    "# convert to RGB\n",
    "pca_embeddings = (\n",
    "    (pca_embeddings - pca_embeddings.min()) / (pca_embeddings.max() - pca_embeddings.min()) * 255\n",
    ").astype(int)\n",
    "\n",
    "# make the rgb array into a string\n",
    "pca_embeddings[\"rgb\"] = pca_embeddings.apply(\n",
    "    lambda row: f\"rgb({row[0]}, {row[1]}, {row[2]})\", axis=1\n",
    ")\n",
    "\n",
    "\n",
    "color_dict = dict(\n",
    "    enumerate(buffered_h3_regions.index.map(pca_embeddings[\"rgb\"].to_dict()).to_list())\n",
    ")\n",
    "buffered_h3_regions.reset_index().reset_index().explore(\n",
    "    column=\"index\",\n",
    "    tooltip=\"region_id\",\n",
    "    tiles=\"CartoDB positron\",\n",
    "    legend=False,\n",
    "    cmap=lambda x: color_dict[x],\n",
    "    style_kwds=dict(color=\"#444\", opacity=0.0, fillOpacity=0.5),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "clusterizer = KMeans(n_clusters=5, random_state=SEED)\n",
    "clusterizer.fit(hex2vec_embeddings)\n",
    "\n",
    "hex2vec_embeddings[\"cluster\"] = clusterizer.labels_\n",
    "hex2vec_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_numeric_data(\n",
    "    buffered_h3_regions, \"cluster\", hex2vec_embeddings, tiles_style=\"CartoDB positron\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
