{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from srai.embedders import GeoVexEmbedder, Hex2VecEmbedder\n",
    "from srai.joiners import IntersectionJoiner\n",
    "from srai.loaders import OSMPbfLoader\n",
    "from srai.loaders.osm_loaders.filters import GEOFABRIK_LAYERS\n",
    "from srai.neighbourhoods import H3Neighbourhood\n",
    "from srai.regionalizers import H3Regionalizer, geocode_to_region_gdf\n",
    "from srai.plotting import plot_regions, plot_numeric_data\n",
    "from srai.h3 import ring_buffer_h3_regions_gdf\n",
    "\n",
    "import warnings\n",
    "\n",
    "from pytorch_lightning import seed_everything\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 71\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data from OSM\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First use geocoding to get the area\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_gdf = geocode_to_region_gdf(\"Wroc≈Çaw, Poland\")\n",
    "plot_regions(area_gdf, tiles_style=\"CartoDB positron\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buffer the Area\n",
    "\n",
    "The GeoVex embedder requires a buffer around the area of interest, as the hexagon needs to have its radius k neighbors in the dataset as well.\n",
    "The buffer is defined in hexagon radius units, so a buffer of 1 means that the hexagon will have its 1-neighborhood in the dataset as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = 9\n",
    "k_ring_buffer_radius = 4\n",
    "\n",
    "regionalizer = H3Regionalizer(resolution=resolution)\n",
    "base_h3_regions = regionalizer.transform(area_gdf)\n",
    "\n",
    "buffered_h3_regions = ring_buffer_h3_regions_gdf(base_h3_regions, distance=k_ring_buffer_radius)\n",
    "buffered_h3_geometry = buffered_h3_regions.unary_union\n",
    "\n",
    "print(\"Base regions:\", len(base_h3_regions))\n",
    "print(\"Buffered regions:\", len(buffered_h3_regions))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the Data\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, download the data for the selected region and the specified tags.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = GEOFABRIK_LAYERS\n",
    "loader = OSMPbfLoader()\n",
    "\n",
    "features_gdf = loader.load(buffered_h3_geometry, tags)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data for embedding\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After downloading the data, we need to prepare it for embedding. In the previous step we have regionalized the selected area and buffered it, now we have to join the features with prepared regions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_regions(buffered_h3_regions, tiles_style=\"CartoDB positron\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joiner = IntersectionJoiner()\n",
    "joint_gdf = joiner.transform(buffered_h3_regions, features_gdf)\n",
    "joint_gdf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GeoVex-Embedding\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After preparing the data we can proceed with generating embeddings for the regions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbourhood = H3Neighbourhood(buffered_h3_regions)\n",
    "\n",
    "embedder = GeoVexEmbedder(\n",
    "    target_features=GEOFABRIK_LAYERS,\n",
    "    batch_size=10,\n",
    "    neighbourhood_radius=k_ring_buffer_radius,\n",
    "    convolutional_layers=2,\n",
    "    embedding_size=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "    embeddings = embedder.fit_transform(\n",
    "        regions_gdf=buffered_h3_regions,\n",
    "        features_gdf=features_gdf,\n",
    "        joint_gdf=joint_gdf,\n",
    "        neighbourhood=neighbourhood,\n",
    "        trainer_kwargs={\n",
    "            # \"max_epochs\": 20, # uncomment for a longer training\n",
    "            \"max_epochs\": 5,\n",
    "            \"accelerator\": (\n",
    "                \"cpu\" if torch.backends.mps.is_available() else \"auto\"\n",
    "            ),  # GeoVexEmbedder does not support MPS\n",
    "        },\n",
    "        learning_rate=0.001,\n",
    "    )\n",
    "\n",
    "embeddings.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hex2Vec Embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbourhood = H3Neighbourhood(buffered_h3_regions)\n",
    "\n",
    "hex2vec_embedder = Hex2VecEmbedder(\n",
    "    encoder_sizes=[300, 150, 50],\n",
    ")\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "    hex2vec_embeddings = hex2vec_embedder.fit_transform(\n",
    "        regions_gdf=buffered_h3_regions,\n",
    "        features_gdf=features_gdf,\n",
    "        joint_gdf=joint_gdf,\n",
    "        neighbourhood=neighbourhood,\n",
    "        negative_sample_k_distance=2,\n",
    "        batch_size=64,\n",
    "        learning_rate=0.001,\n",
    "        trainer_kwargs={\n",
    "            # \"max_epochs\": 50, # uncomment for a longer training\n",
    "            \"max_epochs\": 5,\n",
    "            \"accelerator\": \"auto\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "hex2vec_embeddings.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the Embeddings\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GeoVex Embedding\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do pca with three components and then cast to RGB\n",
    "pca = PCA(n_components=3)\n",
    "\n",
    "pca_embeddings = pca.fit_transform(embeddings)\n",
    "# make the embeddings into a dataframe\n",
    "pca_embeddings = pd.DataFrame(pca_embeddings, index=embeddings.index)\n",
    "\n",
    "# convert to RGB\n",
    "pca_embeddings = (\n",
    "    (pca_embeddings - pca_embeddings.min()) / (pca_embeddings.max() - pca_embeddings.min()) * 255\n",
    ").astype(int)\n",
    "\n",
    "# make the rgb array into a string\n",
    "pca_embeddings[\"rgb\"] = pca_embeddings.apply(\n",
    "    lambda row: f\"rgb({row[0]}, {row[1]}, {row[2]})\", axis=1\n",
    ")\n",
    "\n",
    "\n",
    "color_dict = dict(enumerate(base_h3_regions.index.map(pca_embeddings[\"rgb\"].to_dict()).to_list()))\n",
    "base_h3_regions.reset_index().reset_index().explore(\n",
    "    column=\"index\",\n",
    "    tooltip=\"region_id\",\n",
    "    tiles=\"CartoDB positron\",\n",
    "    legend=False,\n",
    "    cmap=lambda x: color_dict[x],\n",
    "    style_kwds=dict(color=\"#444\", opacity=0.0, fillOpacity=0.5),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterizer = KMeans(n_clusters=5, random_state=SEED)\n",
    "clusterizer.fit(embeddings)\n",
    "embeddings.index.name = \"region_id\"\n",
    "embeddings[\"cluster\"] = clusterizer.labels_\n",
    "embeddings[\"cluster\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_numeric_data(base_h3_regions, \"cluster\", embeddings, tiles_style=\"CartoDB positron\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hex2Vec\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do pca with three components and then cast to RGB\n",
    "pca = PCA(n_components=3)\n",
    "\n",
    "pca_embeddings = pca.fit_transform(hex2vec_embeddings)\n",
    "# make the embeddings into a dataframe\n",
    "pca_embeddings = pd.DataFrame(pca_embeddings, index=hex2vec_embeddings.index)\n",
    "\n",
    "# convert to RGB\n",
    "pca_embeddings = (\n",
    "    (pca_embeddings - pca_embeddings.min()) / (pca_embeddings.max() - pca_embeddings.min()) * 255\n",
    ").astype(int)\n",
    "\n",
    "# make the rgb array into a string\n",
    "pca_embeddings[\"rgb\"] = pca_embeddings.apply(\n",
    "    lambda row: f\"rgb({row[0]}, {row[1]}, {row[2]})\", axis=1\n",
    ")\n",
    "\n",
    "\n",
    "color_dict = dict(enumerate(base_h3_regions.index.map(pca_embeddings[\"rgb\"].to_dict()).to_list()))\n",
    "base_h3_regions.reset_index().reset_index().explore(\n",
    "    column=\"index\",\n",
    "    tooltip=\"region_id\",\n",
    "    tiles=\"CartoDB positron\",\n",
    "    legend=False,\n",
    "    cmap=lambda x: color_dict[x],\n",
    "    style_kwds=dict(color=\"#444\", opacity=0.0, fillOpacity=0.5),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterizer = KMeans(n_clusters=5, random_state=SEED)\n",
    "clusterizer.fit(hex2vec_embeddings)\n",
    "\n",
    "hex2vec_embeddings[\"cluster\"] = clusterizer.labels_\n",
    "hex2vec_embeddings[\"cluster\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_numeric_data(base_h3_regions, \"cluster\", hex2vec_embeddings, tiles_style=\"CartoDB positron\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
