{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import osmnx as ox\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "from srai.embedders import Highway2VecEmbedder\n",
    "from srai.loaders import osm_way_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedder = Highway2VecEmbedder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_place = ox.geocode_to_gdf(\"WrocÅ‚aw, Poland\")\n",
    "gdf_place.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from srai.regionizers import H3Regionizer\n",
    "\n",
    "gdf_regions = H3Regionizer(7).transform(gdf_place)\n",
    "gdf_regions.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osmnx_road_infrastructure_tags = [\n",
    "    \"bridge\",\n",
    "    \"tunnel\",\n",
    "    \"oneway\",\n",
    "    \"lanes\",\n",
    "    \"ref\",\n",
    "    \"name\",\n",
    "    \"highway\",\n",
    "    \"maxspeed\",\n",
    "    \"service\",\n",
    "    \"access\",\n",
    "    \"area\",\n",
    "    \"landuse\",\n",
    "    \"width\",\n",
    "    \"est_width\",\n",
    "    \"junction\",\n",
    "    # missing in the original config\n",
    "    \"surface\",\n",
    "    \"footway\",\n",
    "    \"bicycle\",\n",
    "    \"lit\",\n",
    "]\n",
    "\n",
    "network_type = \"drive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ox.settings.useful_tags_way = osmnx_road_infrastructure_tags\n",
    "ox.settings.timeout = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polygon = gdf_place[\"geometry\"][0]  # TODO: make it work on multiple polygons\n",
    "G_directed = ox.graph_from_polygon(\n",
    "    polygon, network_type=network_type, retain_all=True, clean_periphery=True\n",
    ")\n",
    "G = ox.utils_graph.get_undirected(\n",
    "    G_directed\n",
    ")  # FIXME: takes a really long time, which is weird. Maybe try dropping 'reversed' rows instead\n",
    "ox.plot_graph(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_nodes, gdf_edges = ox.graph_to_gdfs(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = gdf_edges.plot(linewidth=1, figsize=(15, 10))\n",
    "gdf_nodes.plot(ax=ax, markersize=3, color=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keplergl import KeplerGl\n",
    "\n",
    "# m = KeplerGl(height=768, data={\"nodes\": gdf_nodes.copy(), \"edges\": gdf_edges.copy()})\n",
    "# m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = osm_way_loader.OSM_WAY_TAGS.keys()\n",
    "gdf_edges_exploded = gdf_edges\n",
    "for col in cols:\n",
    "    gdf_edges_exploded = gdf_edges_exploded.explode(col)\n",
    "\n",
    "gdf_edges_exploded[\"i\"] = range(0, len(gdf_edges_exploded))\n",
    "gdf_edges_exploded.set_index(\"i\", append=True, inplace=True)\n",
    "gdf_edges_exploded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: preprocess data (normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functional import seq\n",
    "\n",
    "features = (\n",
    "    seq(osm_way_loader.OSM_WAY_TAGS.items())\n",
    "    .flat_map(lambda x: [f\"{x[0]}-{v}\" if x[0] not in [\"oneway\"] else x[0] for v in x[1]])\n",
    "    .distinct()\n",
    "    .to_list()\n",
    ")\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_edges_wide = (\n",
    "    pd.get_dummies(gdf_edges_exploded[cols], prefix_sep=\"-\")\n",
    "    .droplevel(3)\n",
    "    .groupby(level=[0, 1, 2])\n",
    "    .max()\n",
    "    .astype(np.uint8)\n",
    ")\n",
    "# gdf_edges_wide.astype(pd.SparseDtype(np.uint8, 0)).info()\n",
    "\n",
    "display(gdf_edges_wide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_edges_wide = gdf_edges_wide.reindex(columns=features, fill_value=0).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpd.GeoDataFrame(pd.concat([gdf_edges.drop(columns=cols), gdf_edges_wide], axis=1), crs=\"epsg:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "display(torch.cuda.is_available())\n",
    "\n",
    "\n",
    "class LitAutoEncoder(pl.LightningModule):\n",
    "    def __init__(self, in_dim: int, hidden_dim: int = 64, latent_dim: int = 3, lr: float = 1e-3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, latent_dim),\n",
    "            # nn.Tanh()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, in_dim),\n",
    "        )\n",
    "        self.lr = lr\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        return z\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self._common_step(batch, batch_idx, \"train\")\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self._common_step(batch, batch_idx, \"val\")\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return self._common_step(batch, batch_idx, \"test\")\n",
    "\n",
    "    def _prepare_batch(self, batch, batch_idx):\n",
    "        x = batch\n",
    "        # x = x.view(x.size(0), -1)\n",
    "        return x\n",
    "\n",
    "    def _common_step(self, batch, batch_idx, stage: str) -> torch.Tensor:\n",
    "        x = self._prepare_batch(batch, batch_idx)\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        loss = F.mse_loss(x_hat, x)\n",
    "        # loss = F.binary_cross_entropy_with_logits(x_hat, x)\n",
    "\n",
    "        self.log(f\"{stage}_loss\", loss, on_epoch=True, on_step=True, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=self.lr)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.2\n",
    "random_seed = 42\n",
    "batch_size = 128\n",
    "num_workers = 6\n",
    "shuffle = True\n",
    "hidden_dim = 64\n",
    "enc_out_dim = 40\n",
    "latent_dim = 30\n",
    "epochs = 10\n",
    "kl_coeff = 0.1\n",
    "lr = 1e-3\n",
    "n_features = gdf_edges_wide.shape[1]\n",
    "\n",
    "pl.seed_everything(random_seed, workers=True)\n",
    "\n",
    "X = torch.Tensor(gdf_edges_wide.values)\n",
    "X_train, X_test = train_test_split(X, test_size=test_size, random_state=random_seed, shuffle=True)\n",
    "X_train_dl = DataLoader(\n",
    "    X_train, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers, pin_memory=True\n",
    ")\n",
    "X_test_dl = DataLoader(\n",
    "    X_test, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True\n",
    ")\n",
    "\n",
    "model = LitAutoEncoder(in_dim=n_features, hidden_dim=hidden_dim, latent_dim=latent_dim, lr=lr)\n",
    "\n",
    "# logger_tb = pl.loggers.TensorBoardLogger(\"tb_logs\", name=\"test_model\")\n",
    "\n",
    "trainer = pl.Trainer(accelerator=\"gpu\", devices=1, max_epochs=epochs)\n",
    "trainer.fit(model, train_dataloaders=X_train_dl, val_dataloaders=X_test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=lightning_logs/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.14 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "ff171c218963a21ae796a71e1fcf1df45597c5219c663e3cec1d9a9df6951d9c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
